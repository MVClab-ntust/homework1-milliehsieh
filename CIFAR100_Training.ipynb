{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "\n",
    "batch_size = 512\n",
    "trainset, validset = torch.utils.data.random_split(\n",
    "    torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform = transform),\n",
    "    lengths=[40000, 10000])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "validloader = torch.utils.data.DataLoader(validset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('skunk', 'caterpillar', 'aquarium_fish', 'house', 'porcupine', 'castle', 'bear', \n",
    "           'cloud', 'snake', 'rabbit', 'fox', 'maple_tree', 'hamster', 'bed', 'cattle', 'chair', \n",
    "           'seal', 'squirrel', 'couch', 'bottle', 'pine_tree', 'tank', 'keyboard', 'raccoon', \n",
    "           'cockroach', 'pickup_truck', 'orange', 'spider', 'beetle', 'streetcar', 'dinosaur', \n",
    "           'tulip', 'wardrobe', 'lion', 'train', 'clock', 'crab', 'palm_tree', 'rocket', 'forest', \n",
    "           'mouse', 'shrew', 'chimpanzee', 'sweet_pepper', 'tiger', 'telephone', 'road', 'bicycle', \n",
    "           'woman', 'butterfly', 'wolf', 'lizard', 'bus', 'mountain', 'poppy', 'beaver', 'trout', \n",
    "           'man', 'bridge', 'pear', 'plain', 'table', 'ray', 'whale', 'motorcycle', 'crocodile', \n",
    "           'dolphin', 'snail', 'plate', 'cup', 'oak_tree', 'girl', 'apple', 'baby', 'television', \n",
    "           'skyscraper', 'flatfish', 'kangaroo', 'turtle', 'worm', 'elephant', 'lobster', 'tractor', \n",
    "           'bee', 'willow_tree', 'rose', 'can', 'sunflower', 'possum', 'sea', 'bowl', 'otter', 'shark', \n",
    "           'camel', 'lamp', 'lawn_mower', 'mushroom', 'orchid', 'boy', 'leopard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Define a Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.downsample = None\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        out += identity\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self, num_classes=100):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.in_channels = 64\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, self.in_channels, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(BasicBlock, 64, num_blocks=2, stride=1)\n",
    "        self.layer2 = self._make_layer(BasicBlock, 128, num_blocks=2, stride=2)\n",
    "        self.layer3 = self._make_layer(BasicBlock, 256, num_blocks=2, stride=2)\n",
    "        self.layer4 = self._make_layer(BasicBlock, 512, num_blocks=2, stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(512, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, out_channels, num_blocks, stride):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels\n",
    "\n",
    "        for _ in range(1, num_blocks):\n",
    "            layers.append(block(out_channels, out_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "net = ResNet18().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 0   |  Accuracy :  1.07 %\n",
      "Epoch : 0   |  Accuracy :  10.16 %\n",
      "Epoch : 1   |  Accuracy :  13.85 %\n",
      "Epoch : 1   |  Accuracy :  17.27 %\n",
      "Epoch : 2   |  Accuracy :  18.89 %\n",
      "Epoch : 2   |  Accuracy :  21.29 %\n",
      "Epoch : 3   |  Accuracy :  21.96 %\n",
      "Epoch : 3   |  Accuracy :  22.59 %\n",
      "Epoch : 4   |  Accuracy :  23.48 %\n",
      "Epoch : 4   |  Accuracy :  24.64 %\n",
      "Epoch : 5   |  Accuracy :  25.1 %\n",
      "Epoch : 5   |  Accuracy :  25.17 %\n",
      "Epoch : 6   |  Accuracy :  25.33 %\n",
      "Epoch : 6   |  Accuracy :  26.16 %\n",
      "Epoch : 7   |  Accuracy :  26.26 %\n",
      "Epoch : 7   |  Accuracy :  25.82 %\n",
      "Epoch : 8   |  Accuracy :  25.47 %\n",
      "Epoch : 8   |  Accuracy :  26.2 %\n",
      "Epoch : 9   |  Accuracy :  26.07 %\n",
      "Epoch : 9   |  Accuracy :  26.01 %\n",
      "Epoch : 10  |  Accuracy :  25.87 %\n",
      "Epoch : 10  |  Accuracy :  26.19 %\n",
      "Epoch : 11  |  Accuracy :  25.81 %\n",
      "Epoch : 11  |  Accuracy :  26.21 %\n",
      "Epoch : 12  |  Accuracy :  25.27 %\n",
      "Epoch : 12  |  Accuracy :  26.25 %\n",
      "Epoch : 13  |  Accuracy :  26.32 %\n",
      "Epoch : 13  |  Accuracy :  26.62 %\n",
      "Epoch : 14  |  Accuracy :  26.09 %\n",
      "Epoch : 14  |  Accuracy :  26.73 %\n",
      "Epoch : 15  |  Accuracy :  26.1 %\n",
      "Epoch : 15  |  Accuracy :  26.82 %\n",
      "Epoch : 16  |  Accuracy :  26.11 %\n",
      "Epoch : 16  |  Accuracy :  26.62 %\n",
      "Epoch : 17  |  Accuracy :  26.55 %\n",
      "Epoch : 17  |  Accuracy :  26.93 %\n",
      "Epoch : 18  |  Accuracy :  26.61 %\n",
      "Epoch : 18  |  Accuracy :  26.7 %\n",
      "Epoch : 19  |  Accuracy :  26.75 %\n",
      "Epoch : 19  |  Accuracy :  26.48 %\n",
      "Epoch : 20  |  Accuracy :  26.09 %\n",
      "Epoch : 20  |  Accuracy :  26.59 %\n",
      "Epoch : 21  |  Accuracy :  26.67 %\n",
      "Epoch : 21  |  Accuracy :  26.81 %\n",
      "Epoch : 22  |  Accuracy :  26.46 %\n",
      "Epoch : 22  |  Accuracy :  26.83 %\n",
      "Epoch : 23  |  Accuracy :  26.84 %\n",
      "Epoch : 23  |  Accuracy :  26.69 %\n",
      "Epoch : 24  |  Accuracy :  26.88 %\n",
      "Epoch : 24  |  Accuracy :  26.97 %\n",
      "Epoch : 25  |  Accuracy :  26.77 %\n",
      "Epoch : 25  |  Accuracy :  26.71 %\n",
      "Epoch : 26  |  Accuracy :  26.6 %\n",
      "Epoch : 26  |  Accuracy :  26.88 %\n",
      "Epoch : 27  |  Accuracy :  26.8 %\n",
      "Epoch : 27  |  Accuracy :  26.81 %\n",
      "Epoch : 28  |  Accuracy :  26.75 %\n",
      "Epoch : 28  |  Accuracy :  26.49 %\n",
      "Epoch : 29  |  Accuracy :  26.7 %\n",
      "Epoch : 29  |  Accuracy :  27.18 %\n",
      "Epoch : 30  |  Accuracy :  26.83 %\n",
      "Epoch : 30  |  Accuracy :  26.79 %\n",
      "Epoch : 31  |  Accuracy :  26.68 %\n",
      "Epoch : 31  |  Accuracy :  26.7 %\n",
      "Epoch : 32  |  Accuracy :  26.71 %\n",
      "Epoch : 32  |  Accuracy :  26.8 %\n",
      "Epoch : 33  |  Accuracy :  26.82 %\n",
      "Epoch : 33  |  Accuracy :  26.96 %\n",
      "Epoch : 34  |  Accuracy :  26.69 %\n",
      "Epoch : 34  |  Accuracy :  26.63 %\n",
      "Epoch : 35  |  Accuracy :  26.9 %\n",
      "Epoch : 35  |  Accuracy :  26.62 %\n",
      "Epoch : 36  |  Accuracy :  26.7 %\n",
      "Epoch : 36  |  Accuracy :  26.88 %\n",
      "Epoch : 37  |  Accuracy :  26.55 %\n",
      "Epoch : 37  |  Accuracy :  26.57 %\n",
      "Epoch : 38  |  Accuracy :  26.65 %\n",
      "Epoch : 38  |  Accuracy :  26.67 %\n",
      "Epoch : 39  |  Accuracy :  26.57 %\n",
      "Epoch : 39  |  Accuracy :  27.06 %\n",
      "Epoch : 40  |  Accuracy :  26.66 %\n",
      "Epoch : 40  |  Accuracy :  26.7 %\n",
      "Epoch : 41  |  Accuracy :  26.74 %\n",
      "Epoch : 41  |  Accuracy :  27.22 %\n",
      "Epoch : 42  |  Accuracy :  26.88 %\n",
      "Epoch : 42  |  Accuracy :  26.77 %\n",
      "Epoch : 43  |  Accuracy :  26.83 %\n",
      "Epoch : 43  |  Accuracy :  26.97 %\n",
      "Epoch : 44  |  Accuracy :  26.26 %\n",
      "Epoch : 44  |  Accuracy :  26.83 %\n",
      "Epoch : 45  |  Accuracy :  26.72 %\n",
      "Epoch : 45  |  Accuracy :  26.55 %\n",
      "Epoch : 46  |  Accuracy :  26.68 %\n",
      "Epoch : 46  |  Accuracy :  26.66 %\n",
      "Epoch : 47  |  Accuracy :  26.67 %\n",
      "Epoch : 47  |  Accuracy :  26.83 %\n",
      "Epoch : 48  |  Accuracy :  26.91 %\n",
      "Epoch : 48  |  Accuracy :  27.06 %\n",
      "Epoch : 49  |  Accuracy :  27.07 %\n",
      "Epoch : 49  |  Accuracy :  26.62 %\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "# progress_bar = tqdm(enumerate(trainloader, 0), total=len(trainloader), desc='Training')\n",
    "\n",
    "for epoch in range(50):  # epoch\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        net.train()\n",
    "        # zero gradient\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward, backward, optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #wandb.log({\"loss\": loss})\n",
    "        #progress_bar.update(1)\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            # validation\n",
    "            net.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            with torch.no_grad():\n",
    "                for data in validloader: \n",
    "                    images, labels = data[0].to(device), data[1].to(device)\n",
    "                    outputs = net(images)\n",
    "                    # the class with the highest energy is what we choose as prediction\n",
    "                    _, predicted = torch.max(outputs.data, 1)\n",
    "                    total += labels.size(0)\n",
    "                    correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            print(\"Epoch : \" + \"{:<3}\".format(epoch) + \" |  Accuracy : \" + \"{:<4}\".format(100. * correct / total) + \"%\")\n",
    "        running_loss = 0.0\n",
    "\n",
    "\n",
    "print('Finished Training')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 26.19 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "# since we're not training, we don't need to calculate the gradients for our outputs\n",
    "with torch.no_grad():\n",
    "    for data in testloader: \n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Test Accuracy: {100 * correct / total} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n"
     ]
    }
   ],
   "source": [
    "torch.save(net, './data/model_train.pt')\n",
    "print('Model Saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
